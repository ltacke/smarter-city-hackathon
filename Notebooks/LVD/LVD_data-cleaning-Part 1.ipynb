{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Skript for Live Vehicle Data Cleaning - Part 1\n","\n","<strong><em>Important: This is a guide, which helps and explains you the data cleaning we where doing before this Hack-a-thon. There are parts you can and sometimes should directly copy and paste. You won't be able to copy the whole notebook and run it within your project.</em></strong>\n","\n","## Creating the Client Connection to the Cloud Object Storage and the \"smart-city-live-vehicle-positions\" bucket\n","\n","The following code cell can be automatically inserted trough the Notebook UI. To do so, click on the data button (top right corner) there you find the *files* and *connections* tab. Go to the *connection* as we want to create a client to our Cloud Object Storage. \n","\n","There you will find the Connection which we created before. Click \"insert to code\" and choose the \"StreamingBody object\" option. After that there will open a pop up which showes you the folder structure of your underlying cloud bucket. Choose the right folders and subfolders until you end up in the last subfolder, that contains all the .json files we need. Choose one file and click *Select*. Next you will see a code cell, inserted automatically, that looks like this one except it contains the correct api-keys etc.\n","\n","> It doesn't matter which .json you will choose, because we will later on only use the created client object to access more then only one .json file."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# @hidden_cell\n","\n","\n","# This connection object is used to access your data and contains your credentials or project token.\n","# You might want to remove those credentials before you share your notebook.\n","\n","\n","import types\n","import pandas as pd\n","import ibm_boto3\n","from botocore.client import Config\n","\n","def __iter__(self): return 0\n","\n","# @hidden_cell\n","# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n","# You might want to remove those credentials before you share your notebook.\n","\n","Cloud_Object_Storage_Connection_client = ibm_boto3.client(\n","    service_name='s3',\n","    ibm_api_key_id='api-key',\n","    ibm_service_instance_id='service-instance-id',\n","    ibm_auth_endpoint='https://iam.cloud.ibm.com/identity/token',\n","    config=Config(signature_version='oauth'),\n","    endpoint_url='https://s3.eu-de.cloud-object-storage.appdomain.cloud'\n",")\n","\n","body = Cloud_Object_Storage_Connection_client.get_object(Bucket='smart-city-live-vehicle-positions', Key='topics/open_HFP_API/partition=0/open_HFP_API+0+0054722848.json')['Body']\n","# add missing __iter__ method, so pandas accepts body as file-like object \n","\n","if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n","\n","# Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face an error during data loading.\n","# Refer to the documentation of 'pandas.read_json()' and 'pandas.io.json.json_normalize' for more possibilities to adjust the data loading.\n","# pandas documentation: http://pandas.pydata.org/pandas-docs/stable/io.html#io-json-reader\n","# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html\n"]},{"cell_type":"markdown","metadata":{},"source":["After we sucsessfully created the client (your's might be named differently than `Cloud_Object_Storage_Connection_client`, either change it in the cell above or keep in mind to change the name whenever the client is used) we now need a function that can read/get/access more than one .json file. \n","\n","As we know, the data is saved in a S3 object style. The following cell shows the function we use to access files over a given timespan in which they were written to the storage. (Don't stress about the function and how it works in detail ðŸ˜‰) Just copy and paste it.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import argparse\n","import boto3\n","import dateutil.parser\n","import logging\n","import pytz\n","from collections import namedtuple\n","\n","import pandas as pd\n","from datetime import datetime, timezone, timedelta\n","\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","Rule = namedtuple('Rule', ['has_min', 'has_max'])\n","last_modified_rules = {\n","    Rule(has_min=True, has_max=True):\n","        lambda min_date, date, max_date: min_date <= date <= max_date,\n","    Rule(has_min=True, has_max=False):\n","        lambda min_date, date, max_date: min_date <= date,\n","    Rule(has_min=False, has_max=True):\n","        lambda min_date, date, max_date: date <= max_date,\n","    Rule(has_min=False, has_max=False):\n","        lambda min_date, date, max_date: True,\n","}\n","\n","def get_s3_objects(s3, bucket, prefixes=None, suffixes=None, last_modified_min=None, last_modified_max=None):\n","    \n","    if last_modified_min and last_modified_max and last_modified_max < last_modified_min:\n","        raise ValueError(\n","            \"When using both, last_modified_max: {} must be greater than last_modified_min: {}\".format(\n","                last_modified_max, last_modified_min\n","            )\n","        )\n","    # Use the last_modified_rules dict to lookup which conditional logic to apply\n","    # based on which arguments were supplied\n","    last_modified_rule = last_modified_rules[bool(last_modified_min), bool(last_modified_max)]\n","\n","    if not prefixes:\n","        prefixes = ('',)\n","    else:\n","        prefixes = tuple(set(prefixes))\n","    if not suffixes:\n","        suffixes = ('',)\n","    else:\n","        suffixes = tuple(set(suffixes))\n","\n","    kwargs = {'Bucket': bucket}\n","\n","    for prefix in prefixes:\n","        kwargs['Prefix'] = prefix\n","        while True:\n","            # The S3 API response is a large blob of metadata.\n","            # 'Contents' contains information about the listed objects.\n","            resp = s3.list_objects_v2(**kwargs)\n","            for content in resp.get('Contents', []):\n","                last_modified_date = content['LastModified']\n","                if (\n","                    content['Key'].endswith(suffixes) and\n","                    last_modified_rule(last_modified_min, last_modified_date, last_modified_max)\n","                ):\n","                    yield content\n","\n","            # The S3 API is paginated, returning up to 1000 keys at a time.\n","            # Pass the continuation token into the next response, until we\n","            # reach the final page (when this field is missing).\n","            try:\n","                kwargs['ContinuationToken'] = resp['NextContinuationToken']\n","            except KeyError:\n","                break"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the Timespan, which jsons/S3 objects will be collected\n","\n","As introduced right before this, we are able to access data from LVD trough our client and define a timespan in which we want to get the data.\n","\n","We decided to create three variables:\n","`dateloading`,\n","`starttime`,\n","`endtime`, to create the timespan we were talking about. \n","\n","> Even for a few hours the data that has been collected can sum up to 1.000.000+ rows. So to get a feeling of the data cleaning process it is more than enough to create a small timespan (one hour). Also do remember that it is possible, if you change date and time, that there is no data available."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dateloading = \"2022-02-26\"\n","starttime = datetime.fromisoformat(dateloading + ' 12:00:00.000+00:00')\n","endtime = datetime.fromisoformat(dateloading + ' 13:00.000+00:00')"]},{"cell_type":"markdown","metadata":{},"source":["Because the data amount is so large, we needed to access the data day by day and within that day in a few hour steps."]},{"cell_type":"markdown","metadata":{},"source":["Trough the `Cloud_Object_Storage_Connection` and with the usage of the defined method `get_s3_objects` we are now able to access our s3 objects, that were written within the defined timewindow."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["objs=get_s3_objects(s3=Cloud_Object_Storage_Connection_client,bucket=\"smart-city-live-vehicle-positions\", last_modified_min=starttime, last_modified_max=endtime)"]},{"cell_type":"markdown","metadata":{},"source":["The variable `objs` is now filled with these s3 Objects, which isn't a format we can really work with in terms of the final data in form of .json. So it requires one more step to extract the wanted data into our pandas.DataFrame."]},{"cell_type":"markdown","metadata":{},"source":["## Reading the Vehicle Positions from the variable objs and store them into a DataFrame"]},{"cell_type":"markdown","metadata":{},"source":["To receive our data, we use the variable `objs` and iterate trough every `obj` that it contains. We have defined an empty DataFrame (`df_lvd`) which will be filled step by step with the data we want to extract. To do so, we have to use our client again. We use `.get_object()`, give it the exact Bucket we want to access and the Key to our data, which is stored in each `obj['Key']['Body']` and read the lines we \"find\" there which are in the .json format. Around that call, we use `pd.read_json()` to extract the data from the json. This input (now in the form of a DataFrame) is now passed to the self defined method `extract_data()` that extracts all the \"VP\" (VehiclePosition) related data, deletes all empty rows, makes a list out of it (to eliminate format issues) and writes it back into a pd.DataFrame form.\n","\n","This is passed back to the iterational loop, where it is appended to the `df_lvd`. After extracting all the jsons from all the given `obj` out of `objs`, we finally reset the index and drop the old one."]},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":true},"outputs":[],"source":["def extract_data(df_temp):\n","    df_temp = df_temp['VP']\n","    df_temp = df_temp.dropna()\n","    df_temp = df_temp.tolist()\n","    df_temp = pd.DataFrame.from_records(df_temp)\n","    return df_temp\n","\n","df_lvd = pd.DataFrame()\n","for obj in objs:\n","    df_lvd = df_lvd.append(extract_data(pd.read_json(Cloud_Object_Storage_Connection_client.get_object(Bucket='smart-city-live-vehicle-positions', Key=obj['Key'])['Body'].read(), lines=True)))   \n","\n","df_lvd = df_lvd.reset_index(drop = True)"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's take a look if that worked out"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>acc</th>\n","      <th>drst</th>\n","      <th>loc</th>\n","      <th>spd</th>\n","      <th>line</th>\n","      <th>jrn</th>\n","      <th>dl</th>\n","      <th>start</th>\n","      <th>hdg</th>\n","      <th>tsi</th>\n","      <th>...</th>\n","      <th>stop</th>\n","      <th>occu</th>\n","      <th>veh</th>\n","      <th>desi</th>\n","      <th>oper</th>\n","      <th>odo</th>\n","      <th>lat</th>\n","      <th>oday</th>\n","      <th>seq</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>GPS</td>\n","      <td>0.00</td>\n","      <td>588</td>\n","      <td>8.0</td>\n","      <td>299.0</td>\n","      <td>10:04</td>\n","      <td>237.0</td>\n","      <td>1646899191</td>\n","      <td>...</td>\n","      <td>1453132</td>\n","      <td>0</td>\n","      <td>820</td>\n","      <td>801</td>\n","      <td>47</td>\n","      <td>0.0</td>\n","      <td>60.209848</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>GPS</td>\n","      <td>0.00</td>\n","      <td>120</td>\n","      <td>895.0</td>\n","      <td>119.0</td>\n","      <td>10:01</td>\n","      <td>224.0</td>\n","      <td>1646899191</td>\n","      <td>...</td>\n","      <td>1431183</td>\n","      <td>0</td>\n","      <td>1051</td>\n","      <td>86</td>\n","      <td>22</td>\n","      <td>94.0</td>\n","      <td>60.194654</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.1</td>\n","      <td>0.0</td>\n","      <td>GPS</td>\n","      <td>12.14</td>\n","      <td>964</td>\n","      <td>923.0</td>\n","      <td>-129.0</td>\n","      <td>09:14</td>\n","      <td>63.0</td>\n","      <td>1646899191</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>41</td>\n","      <td>506</td>\n","      <td>30</td>\n","      <td>12966.0</td>\n","      <td>60.233694</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.5</td>\n","      <td>NaN</td>\n","      <td>GPS</td>\n","      <td>12.08</td>\n","      <td>769</td>\n","      <td>57.0</td>\n","      <td>-166.0</td>\n","      <td>09:40</td>\n","      <td>335.0</td>\n","      <td>1646899191</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>1124</td>\n","      <td>322</td>\n","      <td>22</td>\n","      <td>NaN</td>\n","      <td>60.210779</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.1</td>\n","      <td>NaN</td>\n","      <td>GPS</td>\n","      <td>38.12</td>\n","      <td>284</td>\n","      <td>9651.0</td>\n","      <td>-50.0</td>\n","      <td>09:40</td>\n","      <td>25.0</td>\n","      <td>1646899191</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>6317</td>\n","      <td>R</td>\n","      <td>90</td>\n","      <td>NaN</td>\n","      <td>60.367697</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>111027</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>GPS</td>\n","      <td>0.00</td>\n","      <td>244</td>\n","      <td>452.0</td>\n","      <td>-346.0</td>\n","      <td>09:12</td>\n","      <td>234.0</td>\n","      <td>1646899313</td>\n","      <td>...</td>\n","      <td>1130113.0</td>\n","      <td>0</td>\n","      <td>1015</td>\n","      <td>212</td>\n","      <td>22</td>\n","      <td>19654.0</td>\n","      <td>60.170823</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>111028</th>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>ODO</td>\n","      <td>NaN</td>\n","      <td>636</td>\n","      <td>8636.0</td>\n","      <td>59.0</td>\n","      <td>09:28</td>\n","      <td>NaN</td>\n","      <td>1646899313</td>\n","      <td>...</td>\n","      <td>4530501.0</td>\n","      <td>0</td>\n","      <td>1035</td>\n","      <td>P</td>\n","      <td>90</td>\n","      <td>25909.0</td>\n","      <td>NaN</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>111029</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>GPS</td>\n","      <td>0.00</td>\n","      <td>973</td>\n","      <td>921.0</td>\n","      <td>299.0</td>\n","      <td>09:35</td>\n","      <td>94.0</td>\n","      <td>1646899309</td>\n","      <td>...</td>\n","      <td>1370108.0</td>\n","      <td>0</td>\n","      <td>833</td>\n","      <td>61T</td>\n","      <td>6</td>\n","      <td>10204.0</td>\n","      <td>60.241650</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>111030</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>GPS</td>\n","      <td>0.00</td>\n","      <td>973</td>\n","      <td>921.0</td>\n","      <td>299.0</td>\n","      <td>09:35</td>\n","      <td>94.0</td>\n","      <td>1646899310</td>\n","      <td>...</td>\n","      <td>1370108.0</td>\n","      <td>0</td>\n","      <td>833</td>\n","      <td>61T</td>\n","      <td>6</td>\n","      <td>10204.0</td>\n","      <td>60.241650</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>111031</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>GPS</td>\n","      <td>0.00</td>\n","      <td>973</td>\n","      <td>921.0</td>\n","      <td>299.0</td>\n","      <td>09:35</td>\n","      <td>94.0</td>\n","      <td>1646899311</td>\n","      <td>...</td>\n","      <td>1370108.0</td>\n","      <td>0</td>\n","      <td>833</td>\n","      <td>61T</td>\n","      <td>6</td>\n","      <td>10204.0</td>\n","      <td>60.241650</td>\n","      <td>2022-03-10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>111032 rows Ã— 24 columns</p>\n","</div>"],"text/plain":["        acc  drst  loc    spd line     jrn     dl  start    hdg         tsi  \\\n","0       0.0   0.0  GPS   0.00  588     8.0  299.0  10:04  237.0  1646899191   \n","1       0.0   1.0  GPS   0.00  120   895.0  119.0  10:01  224.0  1646899191   \n","2       0.1   0.0  GPS  12.14  964   923.0 -129.0  09:14   63.0  1646899191   \n","3       0.5   NaN  GPS  12.08  769    57.0 -166.0  09:40  335.0  1646899191   \n","4      -0.1   NaN  GPS  38.12  284  9651.0  -50.0  09:40   25.0  1646899191   \n","...     ...   ...  ...    ...  ...     ...    ...    ...    ...         ...   \n","111027  0.0   1.0  GPS   0.00  244   452.0 -346.0  09:12  234.0  1646899313   \n","111028  NaN   1.0  ODO    NaN  636  8636.0   59.0  09:28    NaN  1646899313   \n","111029  0.0   1.0  GPS   0.00  973   921.0  299.0  09:35   94.0  1646899309   \n","111030  0.0   1.0  GPS   0.00  973   921.0  299.0  09:35   94.0  1646899310   \n","111031  0.0   1.0  GPS   0.00  973   921.0  299.0  09:35   94.0  1646899311   \n","\n","        ...       stop  occu   veh desi oper      odo        lat        oday  \\\n","0       ...    1453132     0   820  801   47      0.0  60.209848  2022-03-10   \n","1       ...    1431183     0  1051   86   22     94.0  60.194654  2022-03-10   \n","2       ...       None     0    41  506   30  12966.0  60.233694  2022-03-10   \n","3       ...       None     0  1124  322   22      NaN  60.210779  2022-03-10   \n","4       ...       None     0  6317    R   90      NaN  60.367697  2022-03-10   \n","...     ...        ...   ...   ...  ...  ...      ...        ...         ...   \n","111027  ...  1130113.0     0  1015  212   22  19654.0  60.170823  2022-03-10   \n","111028  ...  4530501.0     0  1035    P   90  25909.0        NaN  2022-03-10   \n","111029  ...  1370108.0     0   833  61T    6  10204.0  60.241650  2022-03-10   \n","111030  ...  1370108.0     0   833  61T    6  10204.0  60.241650  2022-03-10   \n","111031  ...  1370108.0     0   833  61T    6  10204.0  60.241650  2022-03-10   \n","\n","        seq  label  \n","0       NaN    NaN  \n","1       NaN    NaN  \n","2       NaN    NaN  \n","3       NaN    NaN  \n","4       NaN    NaN  \n","...     ...    ...  \n","111027  NaN    NaN  \n","111028  NaN    NaN  \n","111029  NaN    NaN  \n","111030  NaN    NaN  \n","111031  NaN    NaN  \n","\n","[111032 rows x 24 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df_lvd"]},{"cell_type":"markdown","metadata":{},"source":["How many rows x columns do we have at hand? "]},{"cell_type":"code","execution_count":9,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["(111032, 24)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_lvd.shape"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":1}
