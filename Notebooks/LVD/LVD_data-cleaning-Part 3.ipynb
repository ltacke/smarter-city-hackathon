{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Skript for Live Vehicle Data Cleaning - Part 3\n","\n","<strong><em>Important: This is a guide, which helps and explains you the data cleaning we where doing before this Hack-a-thon. There are parts you can and sometimes should directly copy and paste. You won't be able to copy the whole notebook and run it within your project.</em></strong>\n","\n","## Creating the Client Connection to the Cloud Object Storage and the \"smart-city-live-vehicle-positions\" bucket\n","\n","The following code cell can be automatically inserted trough the Notebook UI. To do so, click on the data button (top right corner) there you find the *files* and *connections* tab. Go to the *connection* as we want to create a client to our Cloud Object Storage. \n","\n","There you will find the Connection which we created before. Click \"insert to code\" and choose the \"StreamingBody object\" option. After that there will open a pop up which showes you the folder structure of your underlying cloud bucket. Choose the right folders and subfolders until you end up in the last subfolder, that contains all the .json files we need. Choose one file and click *Select*. Next you will see a code cell, inserted automatically, that looks like this one except it contains the correct api-keys etc.\n","\n","> It doesn't matter which .json you will choose, because we will later on only use the created client object to access more then only one .json file."]},{"cell_type":"markdown","metadata":{},"source":["## Converting the tst into a other timestamp format \n","\n","We want to do this, because\n","1. SPSS Modeller don't understand the given format in `tst`\n","2. We maybe want to enrich the data by JOIN it with another resource.\n","   \n","So we define a method, which takes every `tst` value and save a changed version of that into a list, which becomes a new column after that."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\n","\n","date = []\n","hour = []\n","\n","for x in df_lvd_cleaned.tst:\n","    x = x[:-11]\n","    date_obj = datetime.datetime.strptime(x, '%Y-%m-%dT%H')\n","    date.append(str(date_obj.date()) + \" \" + str(date_obj.time()))\n","    \n","date"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["df_lvd_cleaned['timestamp'] = date"]},{"cell_type":"markdown","metadata":{},"source":["# Save the data back to our project"]},{"cell_type":"markdown","metadata":{},"source":["If we think we are finished with cleaning our data, which doesn't have to mean you have the exact same result, we want to extract the data out of the notebook and back into our project space. There we can use it as a data asset. \n","\n","To do so, we use the python libary `project_lib` and import `Project` from it. This gives us the needed functionality, to save the data (dataFrame is converted trough a pandas.DataFrame method named `to_csv()` into a csv format) back to our project space where it can be found as an data asset. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# @hidden_cell\n","# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n","from project_lib import Project\n","project = Project(project_id='id', project_access_token='access-token')\n","pc = project.project_context\n","\n","project.save_data(data=df_lvd_cleaned.to_csv(index=False),file_name=str(dateloading)+'_only_lvd.csv',overwrite=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":1}
