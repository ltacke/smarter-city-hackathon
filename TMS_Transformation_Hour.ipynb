{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Skript for TMS Data Cleaning\n","\n","<strong><em>Important: This is a guide, which helps and explains you the data cleaning we where doing before this Hack-a-thon. There are parts you can and sometimes should directly copy and paste. You won't be able to copy the whole notebook and run it within your project.</em></strong>\n","\n","## Creating the Client Connection to the Cloud Object Storage and the \"smart-city-live-vehicle-positions\" bucket\n","\n","The following code cell can be automatically inserted trough the Notebook UI. To do so, click on the data button (top right corner) there you find the *files* and *connections* tab. Go to the *connection* as we want to create a client to our Cloud Object Storage. \n","\n","There you will find the Connection which we created before. Click \"insert to code\" and choose the \"StreamingBody object\" option. After that there will open a pop up which showes you the folder structure of your underlying cloud bucket. Choose the right folders and subfolders until you end up in the last subfolder, that contains all the .json files we need. Choose one file and click *Select*. Next you will see a code cell, inserted automatically, that looks like this one except it contains the correct api-keys etc.\n","\n","> It doesn't matter which .json you will choose, because we will later on only use the created client object to access more then only one .json file."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# @hidden_cell\n","\n","\n","# This connection object is used to access your data and contains your credentials or project token.\n","# You might want to remove those credentials before you share your notebook.\n","\n","import os\n","import types\n","import pandas as pd\n","import ibm_boto3\n","from botocore.client import Config\n","import logging\n","\n","def __iter__(self): return 0\n","\n","# @hidden_cell\n","# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n","# You might want to remove those credentials before you share your notebook.\n","\n","connection_TMS_trafficData_client = ibm_boto3.client(\n","    service_name='s3',\n","    ibm_api_key_id='api-key',\n","    ibm_service_instance_id='service-instance-id',\n","    ibm_auth_endpoint='https://iam.cloud.ibm.com/identity/token',\n","    config=Config(signature_version='oauth'),\n","    endpoint_url='https://s3.eu-de.cloud-object-storage.appdomain.cloud'\n",")\n","\n","body = connection_TMS_trafficData_client.get_object(Bucket='smart-city-tms', Key='topics/digitraffic_tms/partition=0/digitraffic_tms+0+0011067000.json')['Body'].read()\n","# add missing __iter__ method, so pandas accepts body as file-like object \n","\n","if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n","\n","# Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face an error during data loading.\n","# Refer to the documentation of 'pandas.read_json()' and 'pandas.io.json.json_normalize' for more possibilities to adjust the data loading.\n","# pandas documentation: http://pandas.pydata.org/pandas-docs/stable/io.html#io-json-reader\n","# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html\n","\n","pd.read_json(body, lines=True)"]},{"cell_type":"markdown","metadata":{},"source":["After we sucsessfully created the client (your's might be named differently than `Cloud_Object_Storage_Connection_client`, either change it in the cell above or keep in mind to change the name whenever the client is used) we now need a function that can read/get/access more than one .json file. \n","\n","As we know, the data is saved in a S3 object style. The following cell shows the function we use to access files over a given timespan in which they were written to the storage. (Don't stress about the function and how it works in detail 😉) Just copy and paste it.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import argparse\n","import boto3\n","import dateutil.parser\n","import logging\n","import pytz\n","from collections import namedtuple\n","\n","import pandas as pd\n","from datetime import datetime, timezone, timedelta\n","\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","Rule = namedtuple('Rule', ['has_min', 'has_max'])\n","last_modified_rules = {\n","    Rule(has_min=True, has_max=True):\n","        lambda min_date, date, max_date: min_date <= date <= max_date,\n","    Rule(has_min=True, has_max=False):\n","        lambda min_date, date, max_date: min_date <= date,\n","    Rule(has_min=False, has_max=True):\n","        lambda min_date, date, max_date: date <= max_date,\n","    Rule(has_min=False, has_max=False):\n","        lambda min_date, date, max_date: True,\n","}\n","\n","def get_s3_objects(s3, bucket, prefixes=None, suffixes=None, last_modified_min=None, last_modified_max=None):\n","    \n","    if last_modified_min and last_modified_max and last_modified_max < last_modified_min:\n","        raise ValueError(\n","            \"When using both, last_modified_max: {} must be greater than last_modified_min: {}\".format(\n","                last_modified_max, last_modified_min\n","            )\n","        )\n","    # Use the last_modified_rules dict to lookup which conditional logic to apply\n","    # based on which arguments were supplied\n","    last_modified_rule = last_modified_rules[bool(last_modified_min), bool(last_modified_max)]\n","\n","    if not prefixes:\n","        prefixes = ('',)\n","    else:\n","        prefixes = tuple(set(prefixes))\n","    if not suffixes:\n","        suffixes = ('',)\n","    else:\n","        suffixes = tuple(set(suffixes))\n","\n","    kwargs = {'Bucket': bucket}\n","\n","    for prefix in prefixes:\n","        kwargs['Prefix'] = prefix\n","        while True:\n","            # The S3 API response is a large blob of metadata.\n","            # 'Contents' contains information about the listed objects.\n","            resp = s3.list_objects_v2(**kwargs)\n","            for content in resp.get('Contents', []):\n","                last_modified_date = content['LastModified']\n","                if (\n","                    content['Key'].endswith(suffixes) and\n","                    last_modified_rule(last_modified_min, last_modified_date, last_modified_max)\n","                ):\n","                    yield content\n","\n","            # The S3 API is paginated, returning up to 1000 keys at a time.\n","            # Pass the continuation token into the next response, until we\n","            # reach the final page (when this field is missing).\n","            try:\n","                kwargs['ContinuationToken'] = resp['NextContinuationToken']\n","            except KeyError:\n","                break"]},{"cell_type":"markdown","metadata":{},"source":["## Defining the Timespan, which jsons/S3 objects will be collected\n","\n","As introduced right before this, we are able to access data from TMS trough our client and define a timespan in which we want to get the data.\n","Further we need Metadata, which might not be written within the choosen timewindow. So leave the metastarttime as it is.\n","\n","We decided to create three variables:\n","`dateloading`,\n","`starttime`,\n","`endtime`, to create the timespan we were talking about. \n","\n","> Even for a few hours the data that has been collected can sum up to 1.000.000+ rows. So to get a feeling of the data cleaning process it is more than enough to create a small timespan (one hour). Also do remember that it is possible, if you change date and time, that there is no data available.\n","\n","The use of metastarttime will explane itself later on."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["dateloading = \"2022-02-25\"\n","#dateloading = str(os.environ['DATE'])\n","starttime = datetime.fromisoformat(dateloading + ' 10:00:00.000+00:00')\n","endtime = datetime.fromisoformat(dateloading + ' 12:00:00.000+00:00')\n","metastarttime = datetime.fromisoformat(\"2022-02-20\" + ' 00:00:00.000+00:00')\n"]},{"cell_type":"markdown","metadata":{},"source":["Trough the `Cloud_Object_Storage_Connection` and with the usage of the defined method `get_s3_objects` we are now able to access our s3 objects, that were written within the defined timewindow."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["objs=get_s3_objects(s3=connection_TMS_trafficData_client,bucket=\"smart-city-tms\", last_modified_min=starttime, last_modified_max=endtime)"]},{"cell_type":"markdown","metadata":{},"source":["The variable `objs` is now filled with these s3 Objects, which isn't a format we can really work with in terms of the final data in form of .json. So it requires one more step to extract the wanted data into our pandas.DataFrame."]},{"cell_type":"markdown","metadata":{},"source":["## Reading the Vehicle Positions from the variable objs and store them into a DataFrame"]},{"cell_type":"markdown","metadata":{},"source":["To receive our data, we use the variable `objs` and iterate trough every `obj` that it contains. We have defined an empty DataFrame (`df_tms`) which will be filled step by step with the data we want to extract. To do so, we have to use our client again. We use `.get_object()`, give it the exact Bucket we want to access and the Key to our data, which is stored in each `obj['Key']['Body']` and read the lines we \"find\" there which are in the .json format. Around that call, we use `pd.read_json()` to extract the data from the json. This input (now in the form of a DataFrame) now will be appended to the `df_tms`. After extracting all the jsons from all the given `obj` out of `objs`, we finally reset the index, drop the old one.\n","\n","We then make a first quick step of Data Cleaning by throwing out the rows, which don't contain a roadStationId since we can't really work with these values when the identification is missing."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df_tms = pd.DataFrame()\n","for obj in objs:\n","    df_tms = df_tms.append(pd.read_json(connection_TMS_trafficData_client.get_object(Bucket='smart-city-tms', Key=obj['Key'])['Body'].read(), lines=True))\n","    \n","df_tms = df_tms.reset_index()\n","df_tms = df_tms[df_tms['roadStationId'].notna()]"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's take a look if that worked out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_tms"]},{"cell_type":"markdown","metadata":{},"source":["How many rows x columns do we have at hand? "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(780280, 15)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_tms.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Converting the tst into a other timestamp format \n","\n","We want to do this, because\n","1. SPSS Modeller don't understand the given format in `tst`\n","2. We maybe want to enrich the data by JOIN it with another resource.\n","   \n","So we define a method, which takes every `tst` value and save a changed version of that into a list, which becomes a new column after that.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import datetime\n","\n","date = []\n","\n","for x in df_tms.measuredTime:\n","    x = x[:-7]\n","    date_obj = datetime.datetime.strptime(x, '%Y-%m-%dT%H')\n","    date.append(str(date_obj.date()) + \" \" + str(date_obj.time()))\n","\n","\n","df_tms[\"timestamp\"] = date"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>oldName</th>\n","      <th>name</th>\n","      <th>sensorUnit</th>\n","      <th>id</th>\n","      <th>shortName</th>\n","      <th>sensorValue</th>\n","      <th>timeWindowStart</th>\n","      <th>timeWindowEnd</th>\n","      <th>lastUpdated</th>\n","      <th>lastError</th>\n","      <th>type</th>\n","      <th>status</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>keskinopeus_5min_liukuva_suunta1_VVAPAAS1</td>\n","      <td>KESKINOPEUS_5MIN_LIUKUVA_SUUNTA1_VVAPAAS1</td>\n","      <td>***</td>\n","      <td>5158.0</td>\n","      <td>LTila1</td>\n","      <td>139.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_5min_liukuva_suunta1_MS1</td>\n","      <td>OHITUKSET_5MIN_LIUKUVA_SUUNTA1_MS1</td>\n","      <td>***</td>\n","      <td>5164.0</td>\n","      <td>MTila1</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_60min_kiintea_suunta2_MS2</td>\n","      <td>OHITUKSET_60MIN_KIINTEA_SUUNTA2_MS2</td>\n","      <td>***</td>\n","      <td>5071.0</td>\n","      <td>MTil2</td>\n","      <td>1.0</td>\n","      <td>2022-03-12T22:00:00Z</td>\n","      <td>2022-03-12T23:00:00Z</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>keskinopeus_60min_kiintea_suunta2</td>\n","      <td>KESKINOPEUS_60MIN_KIINTEA_SUUNTA2</td>\n","      <td>km/h</td>\n","      <td>5057.0</td>\n","      <td>km/h2</td>\n","      <td>103.0</td>\n","      <td>2022-03-12T22:00:00Z</td>\n","      <td>2022-03-12T23:00:00Z</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_5min_liukuva_suunta2_MS2</td>\n","      <td>OHITUKSET_5MIN_LIUKUVA_SUUNTA2_MS2</td>\n","      <td>***</td>\n","      <td>5168.0</td>\n","      <td>MTila2</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index          measuredTime  roadStationId  \\\n","0      0  2022-03-12T23:59:35Z        23575.0   \n","1      1  2022-03-12T23:59:35Z        23575.0   \n","2      2  2022-03-12T23:59:35Z        23575.0   \n","3      3  2022-03-12T23:59:35Z        23575.0   \n","4      4  2022-03-12T23:59:35Z        23575.0   \n","\n","                                     oldName  \\\n","0  keskinopeus_5min_liukuva_suunta1_VVAPAAS1   \n","1         ohitukset_5min_liukuva_suunta1_MS1   \n","2        ohitukset_60min_kiintea_suunta2_MS2   \n","3          keskinopeus_60min_kiintea_suunta2   \n","4         ohitukset_5min_liukuva_suunta2_MS2   \n","\n","                                        name sensorUnit      id shortName  \\\n","0  KESKINOPEUS_5MIN_LIUKUVA_SUUNTA1_VVAPAAS1        ***  5158.0    LTila1   \n","1         OHITUKSET_5MIN_LIUKUVA_SUUNTA1_MS1        ***  5164.0    MTila1   \n","2        OHITUKSET_60MIN_KIINTEA_SUUNTA2_MS2        ***  5071.0     MTil2   \n","3          KESKINOPEUS_60MIN_KIINTEA_SUUNTA2       km/h  5057.0     km/h2   \n","4         OHITUKSET_5MIN_LIUKUVA_SUUNTA2_MS2        ***  5168.0    MTila2   \n","\n","   sensorValue       timeWindowStart         timeWindowEnd lastUpdated  \\\n","0        139.0                   NaN                   NaN         NaN   \n","1          1.0                   NaN                   NaN         NaN   \n","2          1.0  2022-03-12T22:00:00Z  2022-03-12T23:00:00Z         NaN   \n","3        103.0  2022-03-12T22:00:00Z  2022-03-12T23:00:00Z         NaN   \n","4          1.0                   NaN                   NaN         NaN   \n","\n","   lastError type status            timestamp  \n","0        NaN  NaN    NaN  2022-03-12 23:00:00  \n","1        NaN  NaN    NaN  2022-03-12 23:00:00  \n","2        NaN  NaN    NaN  2022-03-12 23:00:00  \n","3        NaN  NaN    NaN  2022-03-12 23:00:00  \n","4        NaN  NaN    NaN  2022-03-12 23:00:00  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_tms.head()"]},{"cell_type":"markdown","metadata":{},"source":["## First \"pre\" cleaning step; drop duplicates `roadStationId`, `id` and `timestamp` \n","\n","We had to do this action at this point of the process, because we figured out over the time, that there are many duplicates in this data. Which significantly slowed down the following calculations. \n","\n","So, by using these three attributes we kind of build a __\"primary key\"__ to make sure, only duplicates are dropped."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["df_tms = df_tms.drop_duplicates(subset=['roadStationId', 'id', 'timestamp'])"]},{"cell_type":"markdown","metadata":{},"source":["Just compare the shape from before (~row 7) and now. We were able to clean a lot of duplicates from the DataFrame."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["(18924, 16)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_tms.shape"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>oldName</th>\n","      <th>name</th>\n","      <th>sensorUnit</th>\n","      <th>id</th>\n","      <th>shortName</th>\n","      <th>sensorValue</th>\n","      <th>timeWindowStart</th>\n","      <th>timeWindowEnd</th>\n","      <th>lastUpdated</th>\n","      <th>lastError</th>\n","      <th>type</th>\n","      <th>status</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>keskinopeus_5min_liukuva_suunta1_VVAPAAS1</td>\n","      <td>KESKINOPEUS_5MIN_LIUKUVA_SUUNTA1_VVAPAAS1</td>\n","      <td>***</td>\n","      <td>5158.0</td>\n","      <td>LTila1</td>\n","      <td>139.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_5min_liukuva_suunta1_MS1</td>\n","      <td>OHITUKSET_5MIN_LIUKUVA_SUUNTA1_MS1</td>\n","      <td>***</td>\n","      <td>5164.0</td>\n","      <td>MTila1</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_60min_kiintea_suunta2_MS2</td>\n","      <td>OHITUKSET_60MIN_KIINTEA_SUUNTA2_MS2</td>\n","      <td>***</td>\n","      <td>5071.0</td>\n","      <td>MTil2</td>\n","      <td>1.0</td>\n","      <td>2022-03-12T22:00:00Z</td>\n","      <td>2022-03-12T23:00:00Z</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>keskinopeus_60min_kiintea_suunta2</td>\n","      <td>KESKINOPEUS_60MIN_KIINTEA_SUUNTA2</td>\n","      <td>km/h</td>\n","      <td>5057.0</td>\n","      <td>km/h2</td>\n","      <td>103.0</td>\n","      <td>2022-03-12T22:00:00Z</td>\n","      <td>2022-03-12T23:00:00Z</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_5min_liukuva_suunta2_MS2</td>\n","      <td>OHITUKSET_5MIN_LIUKUVA_SUUNTA2_MS2</td>\n","      <td>***</td>\n","      <td>5168.0</td>\n","      <td>MTila2</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index          measuredTime  roadStationId  \\\n","0      0  2022-03-12T23:59:35Z        23575.0   \n","1      1  2022-03-12T23:59:35Z        23575.0   \n","2      2  2022-03-12T23:59:35Z        23575.0   \n","3      3  2022-03-12T23:59:35Z        23575.0   \n","4      4  2022-03-12T23:59:35Z        23575.0   \n","\n","                                     oldName  \\\n","0  keskinopeus_5min_liukuva_suunta1_VVAPAAS1   \n","1         ohitukset_5min_liukuva_suunta1_MS1   \n","2        ohitukset_60min_kiintea_suunta2_MS2   \n","3          keskinopeus_60min_kiintea_suunta2   \n","4         ohitukset_5min_liukuva_suunta2_MS2   \n","\n","                                        name sensorUnit      id shortName  \\\n","0  KESKINOPEUS_5MIN_LIUKUVA_SUUNTA1_VVAPAAS1        ***  5158.0    LTila1   \n","1         OHITUKSET_5MIN_LIUKUVA_SUUNTA1_MS1        ***  5164.0    MTila1   \n","2        OHITUKSET_60MIN_KIINTEA_SUUNTA2_MS2        ***  5071.0     MTil2   \n","3          KESKINOPEUS_60MIN_KIINTEA_SUUNTA2       km/h  5057.0     km/h2   \n","4         OHITUKSET_5MIN_LIUKUVA_SUUNTA2_MS2        ***  5168.0    MTila2   \n","\n","   sensorValue       timeWindowStart         timeWindowEnd lastUpdated  \\\n","0        139.0                   NaN                   NaN         NaN   \n","1          1.0                   NaN                   NaN         NaN   \n","2          1.0  2022-03-12T22:00:00Z  2022-03-12T23:00:00Z         NaN   \n","3        103.0  2022-03-12T22:00:00Z  2022-03-12T23:00:00Z         NaN   \n","4          1.0                   NaN                   NaN         NaN   \n","\n","   lastError type status            timestamp  \n","0        NaN  NaN    NaN  2022-03-12 23:00:00  \n","1        NaN  NaN    NaN  2022-03-12 23:00:00  \n","2        NaN  NaN    NaN  2022-03-12 23:00:00  \n","3        NaN  NaN    NaN  2022-03-12 23:00:00  \n","4        NaN  NaN    NaN  2022-03-12 23:00:00  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_tms.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Loading metadata\n","\n","By now TMS comes with the value `roadStationId`, which don't provides us directly with a given position in Finland. To overcome that missing information, the TMS-API also provides us with metadata information about the `roadStationId`s. \n","These metadata informations are also written into the same object storage, within a different bucket (`smart-city-tms-stations-metadata`). The value of `metastarttime` has been set beforehand and is choosen to be larger than the starttime, because it can occure that TMS data about certain `roadStationId`s is available, but there is no metadata available within the same timewindow. So we choose a bigger one, to cover all the possible `roadStaionId`s. "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["#metadaten der TMS Stations\n","objs_tms_meta=get_s3_objects(s3=connection_TMS_trafficData_client,bucket=\"smart-city-tms-stations-metadata\", last_modified_min=metastarttime, last_modified_max=endtime)\n","df_tms_meta = pd.DataFrame()\n","\n","for obj in objs_tms_meta:\n","    if df_tms_meta.empty:\n","        df_tms_meta = pd.read_json(connection_TMS_trafficData_client.get_object(Bucket='smart-city-tms-stations-metadata', Key=obj['Key'])['Body'].read(), lines=True)\n","    else:\n","        df_tms_meta_tmp = pd.read_json(connection_TMS_trafficData_client.get_object(Bucket='smart-city-tms-stations-metadata', Key=obj['Key'])['Body'].read(), lines=True)\n","        df_tms_meta = df_tms_meta.append(df_tms_meta_tmp)\n","df_tms_meta = df_tms_meta.reset_index()"]},{"cell_type":"markdown","metadata":{},"source":["## Transform metadata\n","\n","In the `df_tms_meta` there are many informations which we don't care about, we only want to access the geometry data. after that, we collect the columns `['longitude', 'latitude']` to start building our DataFrame (`df`). Then we take another (support) DataFrame, which only contains the various id's. We reset their indexes, JOIN them and drop all the duplicated `id`s aka `roadStationId`s and empty rows. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Datentransformation\n","df = pd.json_normalize(df_tms_meta['geometry'])\n","print(df)\n","df = pd.DataFrame(df.iloc[:,0].tolist(), columns=['longitude', 'latitude', 'else'])\n","df = df[['latitude', 'longitude']]\n","df2 = df_tms_meta['id']\n","df2 = df2.reset_index()\n","df = df.reset_index()\n","df = df.join(df2.set_index('index'), on='index', how='inner')\n","df = df[['latitude', 'longitude', 'id']]\n","df = df.rename(columns={'id': 'roadStationId'})\n","df = df.drop_duplicates(subset=['roadStationId'])\n","df.dropna()"]},{"cell_type":"markdown","metadata":{},"source":["# Join metadata with tms data\n","\n","Now we have two dataframes: `tms` which does contain all the sensor values and `metadata` that contains the geolocation of every `roadStationId`. \n","\n","So the next steps brings these two DataFrames together (pd.merge()). "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_tms = pd.merge(df_tms, df, left_on='roadStationId', right_on='roadStationId', how='left')"]},{"cell_type":"markdown","metadata":{},"source":["We make sure, that no row went missing and we appended our dataframe with 2 columns `[latitude, longitude]`"]},{"cell_type":"code","execution_count":16,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["(18924, 18)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df_tms.shape"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>oldName</th>\n","      <th>name</th>\n","      <th>sensorUnit</th>\n","      <th>id</th>\n","      <th>shortName</th>\n","      <th>sensorValue</th>\n","      <th>timeWindowStart</th>\n","      <th>timeWindowEnd</th>\n","      <th>lastUpdated</th>\n","      <th>lastError</th>\n","      <th>type</th>\n","      <th>status</th>\n","      <th>timestamp</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>keskinopeus_5min_liukuva_suunta1_VVAPAAS1</td>\n","      <td>KESKINOPEUS_5MIN_LIUKUVA_SUUNTA1_VVAPAAS1</td>\n","      <td>***</td>\n","      <td>5158.0</td>\n","      <td>LTila1</td>\n","      <td>139.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_5min_liukuva_suunta1_MS1</td>\n","      <td>OHITUKSET_5MIN_LIUKUVA_SUUNTA1_MS1</td>\n","      <td>***</td>\n","      <td>5164.0</td>\n","      <td>MTila1</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_60min_kiintea_suunta2_MS2</td>\n","      <td>OHITUKSET_60MIN_KIINTEA_SUUNTA2_MS2</td>\n","      <td>***</td>\n","      <td>5071.0</td>\n","      <td>MTil2</td>\n","      <td>1.0</td>\n","      <td>2022-03-12T22:00:00Z</td>\n","      <td>2022-03-12T23:00:00Z</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>keskinopeus_60min_kiintea_suunta2</td>\n","      <td>KESKINOPEUS_60MIN_KIINTEA_SUUNTA2</td>\n","      <td>km/h</td>\n","      <td>5057.0</td>\n","      <td>km/h2</td>\n","      <td>103.0</td>\n","      <td>2022-03-12T22:00:00Z</td>\n","      <td>2022-03-12T23:00:00Z</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>ohitukset_5min_liukuva_suunta2_MS2</td>\n","      <td>OHITUKSET_5MIN_LIUKUVA_SUUNTA2_MS2</td>\n","      <td>***</td>\n","      <td>5168.0</td>\n","      <td>MTila2</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index          measuredTime  roadStationId  \\\n","0      0  2022-03-12T23:59:35Z        23575.0   \n","1      1  2022-03-12T23:59:35Z        23575.0   \n","2      2  2022-03-12T23:59:35Z        23575.0   \n","3      3  2022-03-12T23:59:35Z        23575.0   \n","4      4  2022-03-12T23:59:35Z        23575.0   \n","\n","                                     oldName  \\\n","0  keskinopeus_5min_liukuva_suunta1_VVAPAAS1   \n","1         ohitukset_5min_liukuva_suunta1_MS1   \n","2        ohitukset_60min_kiintea_suunta2_MS2   \n","3          keskinopeus_60min_kiintea_suunta2   \n","4         ohitukset_5min_liukuva_suunta2_MS2   \n","\n","                                        name sensorUnit      id shortName  \\\n","0  KESKINOPEUS_5MIN_LIUKUVA_SUUNTA1_VVAPAAS1        ***  5158.0    LTila1   \n","1         OHITUKSET_5MIN_LIUKUVA_SUUNTA1_MS1        ***  5164.0    MTila1   \n","2        OHITUKSET_60MIN_KIINTEA_SUUNTA2_MS2        ***  5071.0     MTil2   \n","3          KESKINOPEUS_60MIN_KIINTEA_SUUNTA2       km/h  5057.0     km/h2   \n","4         OHITUKSET_5MIN_LIUKUVA_SUUNTA2_MS2        ***  5168.0    MTila2   \n","\n","   sensorValue       timeWindowStart         timeWindowEnd lastUpdated  \\\n","0        139.0                   NaN                   NaN         NaN   \n","1          1.0                   NaN                   NaN         NaN   \n","2          1.0  2022-03-12T22:00:00Z  2022-03-12T23:00:00Z         NaN   \n","3        103.0  2022-03-12T22:00:00Z  2022-03-12T23:00:00Z         NaN   \n","4          1.0                   NaN                   NaN         NaN   \n","\n","   lastError type status            timestamp   latitude  longitude  \n","0        NaN  NaN    NaN  2022-03-12 23:00:00  60.486397   26.54646  \n","1        NaN  NaN    NaN  2022-03-12 23:00:00  60.486397   26.54646  \n","2        NaN  NaN    NaN  2022-03-12 23:00:00  60.486397   26.54646  \n","3        NaN  NaN    NaN  2022-03-12 23:00:00  60.486397   26.54646  \n","4        NaN  NaN    NaN  2022-03-12 23:00:00  60.486397   26.54646  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_tms.head()"]},{"cell_type":"markdown","metadata":{},"source":["# TMS Data Cleaning (the real part 😉)\n","\n","We kindof started the cleaning process a bit early with deleting the duplicated rows as described above. Now we really take a deep look into the documentation and the features we have at hand.\n","\n","## Delete all the irrelevant features \n","\n","After looking at the documentation __(https://www.digitraffic.fi/en/road-traffic/lam/)__ and deciding for our self, which features are irrelevant because the way they were measured or what they are about, we decided to drop the following ones:\n","\n","- oldName\n","- sensorUnit\n","- shortName\n","- lastUpdated\n","- lastError\n","- type\n","- status\n","- timeWindowStart\n","- timeWindowEnd\n","\n","> ____‼️____ Note that you don't have to decide the same way we did. Think about what important features you want to keep."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["df_tms_clean = df_tms.drop(['name', 'timeWindowStart', 'timeWindowEnd', 'oldName', 'sensorUnit', 'shortName', 'lastUpdated', 'lastError', 'type', 'status', 'index'], axis=1)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>id</th>\n","      <th>sensorValue</th>\n","      <th>timestamp</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5158.0</td>\n","      <td>139.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5164.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5071.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5057.0</td>\n","      <td>103.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5168.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.54646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           measuredTime  roadStationId      id  sensorValue  \\\n","0  2022-03-12T23:59:35Z        23575.0  5158.0        139.0   \n","1  2022-03-12T23:59:35Z        23575.0  5164.0          1.0   \n","2  2022-03-12T23:59:35Z        23575.0  5071.0          1.0   \n","3  2022-03-12T23:59:35Z        23575.0  5057.0        103.0   \n","4  2022-03-12T23:59:35Z        23575.0  5168.0          1.0   \n","\n","             timestamp   latitude  longitude  \n","0  2022-03-12 23:00:00  60.486397   26.54646  \n","1  2022-03-12 23:00:00  60.486397   26.54646  \n","2  2022-03-12 23:00:00  60.486397   26.54646  \n","3  2022-03-12 23:00:00  60.486397   26.54646  \n","4  2022-03-12 23:00:00  60.486397   26.54646  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_tms_clean.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Subsample after the hourly data\n","(https://www.digitraffic.fi/en/road-traffic/lam/)\n","\n","If you took a look into the documenation of the API, you found that there are IDs for five minute and sixty minute measurements. We decide wo go with the higher aggregation of the data, which contains enough information for now.\n","\n","All the IDs that contain the data for the sixty minute measurements: \n","- 5056\n","- 5057\n","- 5054\n","- 5055\n","- 5067\n","- 5071\n","\n","So we subset our `df_tms_clean` into a new DataFrame: `df_tms_hour`, now containing only the hour data."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["df_tms_hour = df_tms_clean[df_tms_clean.id.isin([5056, 5057, 5054, 5055, 5067, 5071])]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>id</th>\n","      <th>sensorValue</th>\n","      <th>timestamp</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5071.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5057.0</td>\n","      <td>103.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5067.0</td>\n","      <td>2.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>2022-03-12T23:59:45Z</td>\n","      <td>23576.0</td>\n","      <td>5054.0</td>\n","      <td>69.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.514416</td>\n","      <td>26.926898</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>2022-03-12T23:59:45Z</td>\n","      <td>23576.0</td>\n","      <td>5071.0</td>\n","      <td>3.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.514416</td>\n","      <td>26.926898</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            measuredTime  roadStationId      id  sensorValue  \\\n","2   2022-03-12T23:59:35Z        23575.0  5071.0          1.0   \n","3   2022-03-12T23:59:35Z        23575.0  5057.0        103.0   \n","7   2022-03-12T23:59:35Z        23575.0  5067.0          2.0   \n","13  2022-03-12T23:59:45Z        23576.0  5054.0         69.0   \n","17  2022-03-12T23:59:45Z        23576.0  5071.0          3.0   \n","\n","              timestamp   latitude  longitude  \n","2   2022-03-12 23:00:00  60.486397  26.546460  \n","3   2022-03-12 23:00:00  60.486397  26.546460  \n","7   2022-03-12 23:00:00  60.486397  26.546460  \n","13  2022-03-12 23:00:00  60.514416  26.926898  \n","17  2022-03-12 23:00:00  60.514416  26.926898  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df_tms_hour.head()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df_tms_hour = df_tms_hour.reset_index(drop=True)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>id</th>\n","      <th>sensorValue</th>\n","      <th>timestamp</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5071.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5057.0</td>\n","      <td>103.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5067.0</td>\n","      <td>2.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-03-12T23:59:45Z</td>\n","      <td>23576.0</td>\n","      <td>5054.0</td>\n","      <td>69.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.514416</td>\n","      <td>26.926898</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-03-12T23:59:45Z</td>\n","      <td>23576.0</td>\n","      <td>5071.0</td>\n","      <td>3.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.514416</td>\n","      <td>26.926898</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           measuredTime  roadStationId      id  sensorValue  \\\n","0  2022-03-12T23:59:35Z        23575.0  5071.0          1.0   \n","1  2022-03-12T23:59:35Z        23575.0  5057.0        103.0   \n","2  2022-03-12T23:59:35Z        23575.0  5067.0          2.0   \n","3  2022-03-12T23:59:45Z        23576.0  5054.0         69.0   \n","4  2022-03-12T23:59:45Z        23576.0  5071.0          3.0   \n","\n","             timestamp   latitude  longitude  \n","0  2022-03-12 23:00:00  60.486397  26.546460  \n","1  2022-03-12 23:00:00  60.486397  26.546460  \n","2  2022-03-12 23:00:00  60.486397  26.546460  \n","3  2022-03-12 23:00:00  60.514416  26.926898  \n","4  2022-03-12 23:00:00  60.514416  26.926898  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df_tms_hour.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Calculate geographical distance to our choosen central geolocation\n","\n","You may have found that the TMS data is spread all accross the country of Finland. With the knowledge, that there are other data sources at hand, which focus themself around Helsinki, we decided to subsample TMS once again. We only wanted to have TMS data left, that is ~20km around the center of Helsinki.\n","\n","To get a distance measurement from (longitude, latitude) locations, we needed a library called `geopy`. That's the reason, why we started with defining a custom environment. If we would have installed the package right now (which is possible) we would have to restart the kernel, which results in a unnessesary re-calculation of the done work.\n","\n","So we went on GoogleMaps and choose a fixed Lat,Long pair as our central point of measurement. We then calculated every distance from the `roadStationId`s to this point and appended the `df_tms_hour`by one column, that contains the calculated distance."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>measuredTime</th>\n","      <th>roadStationId</th>\n","      <th>id</th>\n","      <th>sensorValue</th>\n","      <th>timestamp</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>distance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5071.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","      <td>94.283255</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5057.0</td>\n","      <td>103.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","      <td>94.283255</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-03-12T23:59:35Z</td>\n","      <td>23575.0</td>\n","      <td>5067.0</td>\n","      <td>2.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.486397</td>\n","      <td>26.546460</td>\n","      <td>94.283255</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-03-12T23:59:45Z</td>\n","      <td>23576.0</td>\n","      <td>5054.0</td>\n","      <td>69.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.514416</td>\n","      <td>26.926898</td>\n","      <td>115.104429</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-03-12T23:59:45Z</td>\n","      <td>23576.0</td>\n","      <td>5071.0</td>\n","      <td>3.0</td>\n","      <td>2022-03-12 23:00:00</td>\n","      <td>60.514416</td>\n","      <td>26.926898</td>\n","      <td>115.104429</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6331</th>\n","      <td>2022-03-13T01:32:05Z</td>\n","      <td>23142.0</td>\n","      <td>5067.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-13 01:00:00</td>\n","      <td>60.736118</td>\n","      <td>25.448445</td>\n","      <td>66.627738</td>\n","    </tr>\n","    <tr>\n","      <th>6332</th>\n","      <td>2022-03-13T01:32:05Z</td>\n","      <td>23142.0</td>\n","      <td>5056.0</td>\n","      <td>107.0</td>\n","      <td>2022-03-13 01:00:00</td>\n","      <td>60.736118</td>\n","      <td>25.448445</td>\n","      <td>66.627738</td>\n","    </tr>\n","    <tr>\n","      <th>6333</th>\n","      <td>2022-03-13T01:32:05Z</td>\n","      <td>23142.0</td>\n","      <td>5057.0</td>\n","      <td>107.0</td>\n","      <td>2022-03-13 01:00:00</td>\n","      <td>60.736118</td>\n","      <td>25.448445</td>\n","      <td>66.627738</td>\n","    </tr>\n","    <tr>\n","      <th>6334</th>\n","      <td>2022-03-13T01:32:05Z</td>\n","      <td>23142.0</td>\n","      <td>5071.0</td>\n","      <td>1.0</td>\n","      <td>2022-03-13 01:00:00</td>\n","      <td>60.736118</td>\n","      <td>25.448445</td>\n","      <td>66.627738</td>\n","    </tr>\n","    <tr>\n","      <th>6335</th>\n","      <td>2022-03-13T01:32:05Z</td>\n","      <td>23142.0</td>\n","      <td>5054.0</td>\n","      <td>33.0</td>\n","      <td>2022-03-13 01:00:00</td>\n","      <td>60.736118</td>\n","      <td>25.448445</td>\n","      <td>66.627738</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6336 rows × 8 columns</p>\n","</div>"],"text/plain":["              measuredTime  roadStationId      id  sensorValue  \\\n","0     2022-03-12T23:59:35Z        23575.0  5071.0          1.0   \n","1     2022-03-12T23:59:35Z        23575.0  5057.0        103.0   \n","2     2022-03-12T23:59:35Z        23575.0  5067.0          2.0   \n","3     2022-03-12T23:59:45Z        23576.0  5054.0         69.0   \n","4     2022-03-12T23:59:45Z        23576.0  5071.0          3.0   \n","...                    ...            ...     ...          ...   \n","6331  2022-03-13T01:32:05Z        23142.0  5067.0          1.0   \n","6332  2022-03-13T01:32:05Z        23142.0  5056.0        107.0   \n","6333  2022-03-13T01:32:05Z        23142.0  5057.0        107.0   \n","6334  2022-03-13T01:32:05Z        23142.0  5071.0          1.0   \n","6335  2022-03-13T01:32:05Z        23142.0  5054.0         33.0   \n","\n","                timestamp   latitude  longitude    distance  \n","0     2022-03-12 23:00:00  60.486397  26.546460   94.283255  \n","1     2022-03-12 23:00:00  60.486397  26.546460   94.283255  \n","2     2022-03-12 23:00:00  60.486397  26.546460   94.283255  \n","3     2022-03-12 23:00:00  60.514416  26.926898  115.104429  \n","4     2022-03-12 23:00:00  60.514416  26.926898  115.104429  \n","...                   ...        ...        ...         ...  \n","6331  2022-03-13 01:00:00  60.736118  25.448445   66.627738  \n","6332  2022-03-13 01:00:00  60.736118  25.448445   66.627738  \n","6333  2022-03-13 01:00:00  60.736118  25.448445   66.627738  \n","6334  2022-03-13 01:00:00  60.736118  25.448445   66.627738  \n","6335  2022-03-13 01:00:00  60.736118  25.448445   66.627738  \n","\n","[6336 rows x 8 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["import geopy\n","from geopy import distance\n","#(Lat, Long)!!\n","#fix ~ middle of Helsinki\n","\n","fix = (60.192059, 24.945831)\n","abstand = []\n","for x in range(len(df_tms_hour)):\n","    distance = geopy.distance.distance((df_tms_hour.latitude[x], df_tms_hour.longitude[x]), fix).km\n","    abstand.append(distance)\n","\n","df_tms_hour['distance'] = abstand\n","df_tms_hour"]},{"cell_type":"markdown","metadata":{},"source":["We than decided to limit the distance, a `roadStationId` has to the central, to 20km and delete this column, since we don't have any further use for it."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["df_tms_core = df_tms_hour[df_tms_hour.distance <= 20]"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["df_tms_core = df_tms_core.reset_index(drop=True)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["df_tms_core = df_tms_core.drop(['distance'], axis=1)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Save the data back to our project"]},{"cell_type":"markdown","metadata":{},"source":["If we think we are finished with cleaning our data, which doesn't have to mean you have the exact same result, we want to extract the data out of the notebook and back into our project space. There we can use it as a data asset. \n","\n","To do so, we use the python libary `project_lib` and import `Project` from it. This gives us the needed functionality, to save the data (dataFrame is converted trough a pandas.DataFrame method named `to_csv()` into a csv format) back to our project space where it can be found as an data asset. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# @hidden_cell\n","# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n","from project_lib import Project\n","project = Project(project_id='project-id', project_access_token='project-access-token')\n","pc = project.project_context\n","\n","\n","project.save_data(data=df_tms_core.to_csv(index=False),file_name=str(dateloading)+\"-only_TMS_hour.csv\",overwrite=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":1}
